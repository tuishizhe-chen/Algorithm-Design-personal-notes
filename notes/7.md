## Lecture 7

### FPT running time 
- Running time of $O(f(k)\cdot\text{poly}(n))$, where $k$ is a parameter.
- Here is an FPT algorithm for the ***Vertex Covering Problem*** (decision version).
  - Observation: Suppose that $e=(u,v)$ is an edge of $G$, then $VC(G)\le k$ is equivalent to $VC(G-u)\le k-1\lor VC(G-v)\le k-1$
  - **The algorithm**: 
    ```plaintext
 function VertexCover(G, k):
 if k < 0:
 return False
 if G has no edges:
 return True
 if |E(G)|> k|V|
 choose an edge (u, v) in G
 return VertexCover (G - u, k - 1) or VertexCover(G - v, k - 1)
    ```
  - The running time: $T(n,k)\le 2T(n-1,k-1)+O(nk)$, so $T(n,k)\le 2^{k+1}nk$. 
  - The best FPT for vertex covering can achieve $1.2738^k\cdot\text{poly}(n)$.
  
### Approximation Algorithms
**The definition of Approximation ratio/factor:**
 $$\alpha= \sup_{I}\frac{\text{SOL}(I)}{\text{OPT}(I)}$$
 for minimization problems and 
 $$\alpha= \sup_{I}\frac{\text{OPT}(I)}{\text{SOL}(I)}$$ 
 for maximization problems.

***PTAS (poly-time approximation scheme)***: Can achieve $1+\epsilon$ approximation factor with polynomial running time.

#### Load Balancing Problem
Description: $n$ jobs (job $j$ has processing time $t_j$) and $m$ machines, our goal is to minimize $\max_{i}(\sum_{j \text{assigned to} M_i}t_j)$.

The load Balancing Problem is NP-hard due to the ***Subset Sum Problem***.

Here is a greedy algorithm to achieve *PTAS* in the Load Balancing Problem: process jobs one by one from the smaller $t_j$ to the bigger $t_j$. Assign the jobs to the machines with the minimum load.

***Analysis:*** We have the following observations (Let $T*$ be the optimal one):
-  $T*\ge\max{t_j}$
- $T*\ge\frac{\sum_{j=1}^{n}t_j}{m}$

Therefore $\text{Solution}\le\frac{\sum_{j=1}^{n}t_j}{m}+\max{t_j}\le 2T*$

The analysis above is ***tight***, i.e., $2$ is the best approximation factor for this algorithm. It's quite easy to give an example.

The ***tightness*** of the analysis is not the same as "The Approximation factor is optimal". Whether the factor $2$ can be optimized is part of ***Inapproximability theory***, a brief understanding of this theory is like "achieving a better approximation factor is NP-hard".

***Improved approximation factor:*** processing jobs one by one from the biggest $t_j$ to the smallest.

**Analysis:** Assume the machine $M_i$ has the biggest load. Let $B$ be the processing time of the job which is lastly added to $M_i$, then $T*=\text{Solution}$ when $M_i$ only has one job. Now we assume that there are at least 2 jobs in $M_i$. Then consider the first $m+1$ jobs, obviously the optimal max-load is at least $t_{m}+t_{m+1}\ge 2t_{m+1}\ge 2B$. Therefore, $\text{Solution}\le B+\frac{\sum_{j=1}^{n}t_j}{m}\le \frac{3}{2}T*$.

#### $k-$center problem: 
Given a metric graph, choose $k$ vertices to form the center $C$ to minimize $\max_{v\in V}d(v, C)$.

Here is an algorithm providing an approximation factor of 2:

```
Guess the optimal solution r (there are at most |E| guesses)
 S = G, C is empty
 while S is not empty:
 choose an arbitrary vertex from S
 C = C + v
 delete all the nodes in V with a distance to v less than or equal to 2 * r
 if: |C| <= k
 return succeed
```

We claim that if our guess is correct ( $\ge$ OPT), then the algorithm will return success because all the vertices in the territory of one center vertex will be deleted from `S` whenever a vertex in this territory is selected to be the `v`.

The algorithm's approximation factor is $2$.

**Optimality**: 2 is the best approximation factor, which means a $(2-\epsilon)$ approximation algorithm can be used to solve the *3-SAT Problem*.

#### Knapsack Problem


***Algorithm:*** we discretize the value at first: Let $b=\frac{\epsilon}{2n}\max_{w_i\le W}{v_i}$, and let $\hat{v_i}=\lceil \frac{v_i}{b}\rceil$. Then DP for the total value (after discretization) and output the greatest total value for which the total weight does not exceed $W$. The dynamic programming algorithm runs in polynomial time.

**Analysis:** We can achieve an approximation factor of $(1+\epsilon)$.  In fact, if the optimal solution is $\{(w^{*}i,v^{*}i)\}$ and our algorithm generated $\{(w_i,v_i), i=1,\dots,n\}$. Then we have that 
$$\sum_{i=1}^{t}v_i = \sum_{i=1}^{t}(b\cdot\hat{v_i}-b\cdot(1-\{\frac{v_i}{b}\}))\ge \sum_{j=1}^{t*}b\cdot\hat{v*j}-tb\ge OPT-nb$$
Note that $OPT\ge \frac{2nb}{\epsilon}$, therefore 
$$Sol\ge OPT\cdot(1-\frac{\epsilon}{2})$$ hence the approximation factor is about $1+\epsilon$


