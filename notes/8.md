## Lecture 8
### Set Cover problem 
$U$ is a set of elements, there are subsets $S_1,\dots,S_m\subset U$ with weights $w_1,\dots,w_m$. The requirement is to find out the set cover with minimum total weight.

***Algorithm*** we implements greedy method, select the new subset with minimum $\frac{w_i}{|\text{new elements contained by }S_i|}$. 

#### Analysis 
Suppose that $S_{i_1},\dots,S_{i_k}$ are the subsets selected by the algorithm in order. Assume that they cover $m_j$ new elements, respectively. Assume that after select the first $j$ subsets $S_{i_1},\dots,S_{i_j}$, there are $n_j$ remained elements. We claim that 
$$\frac{w_{i_{t+1}}}{m_{t+1}}\le \frac{OPT}{n_t}$$
Therefore, $$Solution=\sum{w_{i_t}}\le \sum_{t=1}^{k}\frac{OPT}{n_{t-1}}m_{i_t}=OPT\cdot(\frac{m_1}{n_0}+\frac{m_2}{n_1}+\dots)\\ \le OPT\cdot(\frac{1}{n}+\dots+\frac{1}{n-m_1+1}+\dots)=OPT\cdot(1+\frac{1}{2}+\cdots+\frac{1}{n}) $$
*Note*: It's NP-hard to approximate ***Set Cover Problem*** with a factor of $(1-\epsilon)\log n$

### Linear Programming 
minimize/maximize $2x_1-x_2$ in constraints of some linear inequalities of $x_1,x_2$. A formal description of this problem is minimize/maximize $C^{T}x$ subject to $Ax\le b$, where $x,C\in \mathbb{R}^n$, $A\in M_{m\times n}(\mathbb{R}), b\in\mathbb{R}^m$.

A geometrical understanding of linear programming is $x$ be contained in the intersection of several halfspaces, which is in fact a polyhedron and to minimize/maximize the distance $x$ to a supersurface.

#### Vertex Cover 
there is a natural transform from vertex cover problem to a linear programmin: let variables $x_1,\dots,x_n\in\{0,1\}$ decide the selection: If we choose $v_i$, then set $x_i$ to $1$. We need to minimize $\sum_{i}w_ix_i$ with subject to $x_i+x_j\ge 1$ for arbitrary connected vertices $v_i,v_j$. However, this is a **Integrating Linear Programming(ILP)**, we need to do **LP-relaxation(LPR)** as follow: $\hat{x_i}=\lfloor x_i+0.5\rfloor$. 

It is obvious that this approximating problem is feasible. Considered that $Sol=\sum{w_i\hat{v_i}}\le\sum{2w_iv_i}=2OPT(LPR)\le 2OPT(ILP)$, therefore we can achieve approximate factor of 2.        

#### Set Cover 
Here is a random algorithm based on the method of the *Vertex Cover Problem*. Let $x_1, x_2, \dots, x_m$ be variables in the range of $(0,1)$ that correspond to $m$ sets. We use a linear programming technique to minimize $\sum_{i=1}^{m} x_i w_i$, where $w_i$ are the weights of the sets, subject to $\sum_{e \in S_i} x_i \ge 1$ for any element $e$. Suppose $(x_1, \dots, x_m)$ is the optimal solution for this linear programming problem. We select $S_i$ with probability $x_i$ and repeat this probabilistic selection process $n$ times. We know that the probability that $e$ is not contained in any selected set is:

$$\prod{(1-x_i)^n} = \exp\left(\sum n \log (1-x_i)\right) \le \exp\left(n \cdot \sum (-x_i)\right) \le e^{-n}$$

Therefore, the probability that there exists an element that is not contained in any selected set is less than or equal to $e^{-n} \cdot |S|$, where $S$ is the union of all candidate sets. We set $n$ to be $\log (|S|^2)$, and the success probability is optimal enough. Morever, the approximating ratio is about $O(\log |S|)$ since the optimal solution's total weight is not greater than $\sum x_i$ of expectancy.
#### Max-cut Problem 
#### TSP (Travelling salesman)

similar with Hamilton cycle problem, but visit every vertex at least once, minimize the total length.

***2-Approximating algorithm*** 
Select a generated tree with smallest total weight. We only need to show that we can construct a path such that it traverse all vertices and the total weight is less or equal than 2 times the total weight of the tree selected above. 

we copy the minimum spanning tree and double the edges. Then we can find a Euler cycle in this graph (This is mathematically trivial, and we can implement this by induction). The Euler cycle is a path that traverse all vertices with total weight less or equal than 2 times the total weight of the minimum spanning tree, therefore less or equal than 2 times the optimal solution.
  