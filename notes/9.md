## Lecture 9 
### Divide and Conquer
An instance of ***Divide and Conquer*** is a reduction sorting algorithm
#### Closest Pair Problem 
Our method is to divide the points into two parts and compute the minimum distance in each fraction respectively and compute the minimum distance that crosses two fractions. 
Here is part of the pseudocode:
```cpp
while (!V.empty()) {
 // Select a line that splits V into two fractions
 // Let d1 be the closest distance in the left half
 // Let d2 be the closest distance in the right half
 // Compute the closest pair that crosses the line
}
```
Computing the closest pair that crosses the line seems to be difficult. Let $\delta$ be the smallest one among `d1` and `d2`. We divide the square into size $\delta/2$ subsquares, where the division line $l$ overlaps with the edges of some subsquares. 
Here is a figure to illustrate the method:

<!-- insert a figure -->


The key observation is that there is at most one point in each subsquare, therefore for arbitrary point $A$, we only need to check about $O(1)$ subsquare to figure out if there exists a point such that it is less than $\delta$ away from $A$ and record the shortest distance of $A$ with points in the other fraction. Thus the computation of whether there exists a pair of points crosses the line with a distance not greater than $\delta$, and what the closest pair if there really exists only costs $O(n)$ times.

#### Select the kth element
##### The randomized algorithm
To select the k-th smallest element from an unsorted array, we can use the **Divide and Conquer** method. This approach is similar to the QuickSort algorithm.
***Algorithm:***
1. **Partition** Randomly select a pivot position to divide the elements into 2 fractions, this process costs $O(m)$ times, where $m$ is the available elements recently. 
2. **Recur**:
  - If the pivot position is the k-th position, return the pivot.
  - If the k-th position is less than the pivot position, recursively apply the algorithm to the left subarray. Similar recursion when the k-th position is greater than the pivot position.
  
***Analysis:***
We say that a recursion is *helpful* if the size of the subarray is less than $\frac{3}{4}$ times of the array. It is obvious that the probability that a recursion is *helpful* is at least $\frac{1}{2}$. Therefore, we record the milestones $M_i$s that the first time the subarray size is less than $n\cdot (\frac{3}{4})^{i}$. Then expected number to successful iterations of reach $M_i$ from $M_{i-1}$ is less than $\sum_{t=1}^{\infty}(\frac{1}{2}^t\cdot O(t))=O(1)$, therefore the expected time is less or equal than 
$$\sum_{i=1}^{O(\log n)}(\frac{3}{4})^{i-1}O(n)\cdot\mathbb{E}(\text{iterations that reach } M_i\text{ from }M_{i-1})=O(n)$$

##### The determined algorithm
We divide the elements into $\frac{n}{5}$ groups. Select the median of each group, and use the median of the medians to be the pivot position. 

***Complexity Analysis***
$$f(n)\le O(n)+f(\frac{n}{5})+\max\{f(\frac{3}{10}n), f(\frac{7}{10}n)\}\le O(n)+f(\frac{n}{5})+f(\frac{7}{10}n)$$
Therefore the complexity is $O(n)$

#### Convolution and FFT
***Convolution:*** Input $(a_1,\dots,a_n), (b_1,\dots,b_n)$. Then we define $a*b$ as 
$$(a_0b_0, a_0b_1+a_1b_0, a_0b_2+a_1b_1+a_2b_0, \dots,a_{n-1}b_{n-1})$$ 
In fact, we can view convolution as polynomial multiplication. Our goal is to compute this in $O(n\log n)$ times.

***Algorithm:*** Assume that $n=2^h$ for some positive integer $h$. We select $2n$ points $x_1,\cdots,x_{2n}$, processing the steps as follows:
- Compute $A(x_1), \dots, A(x_{2n}), B(x_1),\cdots, B(x_{2n})$
- $C(x_j)=A(x_j)B(x_j)$
- Reconstruct $C$ from $C(x_j)$s

We let $x_j$ be $e^{\frac{i\cdot 2j\pi}{2n}}$.
1. We denote $a_0+a_2x+\cdots+a_{n-2}x^{\frac{n-2}{2}}$ as $A_{even}(x)$ and $a_1+a_3x+\cdots+a_{n-1}x^{\frac{n-1}{2}}$ as $A_{odd}(x)$. Therefore 
  $$A(x)=A_{even}(x^2)+x\cdot A_{odd}(x^2)$$
